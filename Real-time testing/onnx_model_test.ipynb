{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03a4fc-a81a-4037-ad27-f5756a093de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import onnxruntime as ort\n",
    "import onnx, os, torch, tf2onnx\n",
    "from onnx2pytorch import ConvertModel\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47a320-4a11-40f7-9cc8-39dc77a58e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sess = ort.InferenceSession('PipeSeg_tiny.onnx')\n",
    "inp, out = sess.get_inputs()[0], sess.get_outputs()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee8acc-2509-46b9-aaf6-e987825e5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('/content/drive/MyDrive/PipeSeg/DJI_0463.MP4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6439c333-74a8-4f6c-90f0-d6450f41d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "# Create an object to read\n",
    "# from camera\n",
    "video = cv2.VideoCapture('/content/drive/MyDrive/PipeSeg/DJI_0463.MP4')\n",
    "\n",
    "# We need to check if camera\n",
    "# is opened previously or not\n",
    "if (video.isOpened() == False):\n",
    "\tprint(\"Error reading video file\")\n",
    "\n",
    "# We need to set resolutions.\n",
    "# so, convert them from float to integer.\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "# Below VideoWriter object will create\n",
    "# a frame of above defined The output\n",
    "# is stored in 'filename.avi' file.\n",
    "result = cv2.VideoWriter('output.avi',\n",
    "\t\t\t\t\t\tcv2.VideoWriter_fourcc(*'MJPG'),\n",
    "\t\t\t\t\t\t30, size)\n",
    "\n",
    "c = 0\n",
    "while(True):\n",
    "\tret, frame = video.read()\n",
    "\n",
    "\tif ret == True:\n",
    "\n",
    "\n",
    "\t\tif c % 500 != 0:\n",
    "\t\t\tc+=1\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tprint(c)\n",
    "\t\tframe = cv2.resize(frame, (320, 240)) ## Resize your images according to your model input\n",
    "\t\tframe = frame[:,:,::-1]/255.0 ## If your traning is done on the normalized image otherwise comment this line\n",
    "\t\tplt.imshow(frame)\n",
    "\t\tplt.show()\n",
    "\t\tframe = frame.reshape(1, 240, 320, 3).astype(np.float32) \n",
    "\n",
    "\t\t# pred = m.predict(frame)\n",
    "\n",
    "\t\tpred = sess.run([out.name], {inp.name: frame})[0].reshape(240, 320)\n",
    "\n",
    "\t\tpred = np.where(pred>=0.5, 0, 1)*255 #.astype(np.uint8)\n",
    "\t\tpred = pred.reshape(240, 320).astype(np.uint8)\n",
    "\t\tpred = np.dstack([pred, pred, pred]) ## not necessary,  here we did because we want to stack output(binary) of model with input(RGB) image\n",
    "\t\t# print(np.unique(pred))\n",
    "\t\t# result.write(pred)\n",
    "\n",
    "\t\tplt.imshow(pred)\n",
    "\t\tplt.show()\n",
    "\n",
    "\t\tc += 1\n",
    "\n",
    "\t\t# Press S on keyboard to stop the process\n",
    "\t\tif cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "\t\t\tbreak\n",
    "\n",
    "\n",
    "\n",
    "\t# Break the loop\n",
    "\telse:\n",
    "\t\tbreak\n",
    "\n",
    "video.release()\n",
    "result.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"The video was successfully saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f47b62b-19d7-4601-8427-7f1d3c669d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b0398-4cbf-45f7-a349-cad3eaefee9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917f2c8-398e-4e21-b16c-e6dc1a822134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee1f937-4568-4726-ae73-95b7e0b7d4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
